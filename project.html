<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Projects</title>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <!-- Navigation Bar -->
    <nav class="navbar">
        <div class="nav-container">
            <a href="index.html" class="nav-logo">NITHIN RONTALA</a>
        </div>
    </nav>

    <!-- Projects Section -->
    <section id="projects" class="projects-section">
        <h2>My Projects</h2>
        
        <div class="project-container">
            <!-- Video Analytics Project -->
            <section class="project-card">
                <h1>Video Analytics</h1>
                <img src="1.png" alt="Video Analytics">
                
                <div class="project-details">
                    <h2>Role</h2>
                    <p>Developed a comprehensive end-to-end video analysis tool for editors, integrating face detection, audio transcription, and dashboard playback.</p>
                    <h2>Problem</h2>
                    <p>Video editors and analysts require efficient tools to extract insights from video content, including face detection, audio transcription, and playback, with the flexibility to add new detection modules.</p>
        
                    <h2>Approach</h2>
                    <p>Built an extensible video analytics app using OpenCV for video processing and Whisper for audio transcription. The architecture supports easy integration of additional modules for object/action detection and summarization, providing a dashboard for interactive playback and review.</p>

                    <h2>Technologies Used</h2>
                    <p>Python, OpenCV, Whisper, Dashboard UI</p>
        
                    <h2>Results</h2>
                    <p>The tool streamlines video analysis for editors, enabling automated face detection, accurate audio transcription, and interactive dashboard playback. Its extensible design allows for future enhancements such as object/action detection and content summarization.</p>
                </div>
            </section>

            <!-- Violence Detection Project -->
            <section class="project-card">
                <h1>Violence Detection</h1>
                <img src="violence.jpg" alt="Violence Detection">
                
                <div class="project-details">
                    <h2>Role</h2>
                    <p>Developed the model by training the model with the I3D Algorithm, including research about the issue.</p>
                    <h2>Problem</h2>
                    <p>Detecting violent behavior in real-time through surveillance cameras is a challenging task, often requiring manual intervention. This project aims to automate violence detection using machine learning models.</p>
        
                    <h2>Approach</h2>
                    <p>I developed a model that processes CCTV footage and identifies violent behavior. The model uses deep learning techniques such as CNNs and LSTMs to analyze the video feed. It then alerts security personnel when a violent action is detected.</p>

                    <h2>Technologies Used</h2>
                    <p>Python, TensorFlow, I3D Algorithm, OpenCV</p>
        
                    <h2>Results</h2>
                    <p>The model achieved an accuracy of 92% in detecting violent actions in a controlled environment. It has potential applications in public safety, retail, and law enforcement.</p>
                </div>
            </section>

            <!-- Hand Gesture Recognition Project -->
            <section class="project-card">
                <h1>Hand Gesture Recognition</h1>
                <img src="hand.jpg" alt="Hand Gesture Recognition">
                
                <div class="project-details">
                    <h2>Role</h2>
                    <p>Designed and trained a deep learning model that can recognize various hand gestures with high accuracy.</p>
                    <h2>Problem</h2>
                    <p>Effective communication between individuals who are unable to speak or hear can be challenging. This project aims to bridge that gap using hand gesture recognition technology.</p>
        
                    <h2>Approach</h2>
                    <p>The model uses Convolutional Neural Networks (CNNs) to process images of hand gestures. The system classifies the gestures into predefined categories and displays the corresponding text or action.</p>

                    <h2>Technologies Used</h2>
                    <p>Python, Keras, OpenCV, CNNs</p>
        
                    <h2>Results</h2>
                    <p>The hand gesture recognition model achieved 95% accuracy in recognizing a wide range of gestures. It has the potential to improve communication for individuals with disabilities and in situations requiring silent communication.</p>
                </div>
            </section>

            <!-- Twitter URL-Based Classification Project -->
            <section class="project-card">
                <h1>Twitter URL-Based Classification</h1>
                <img src="twitter.jpg" alt="Twitter URL-Based Classification">
                
                <div class="project-details">
                    <h2>Role</h2>
                    <p>Developed a system to classify and analyze the content of Twitter URLs for better insight extraction.</p>
                    <h2>Problem</h2>
                    <p>With millions of tweets shared daily, classifying content based on URLs is essential to filter important information from noise.</p>
        
                    <h2>Approach</h2>
                    <p>This project involves building a machine learning model that analyzes URLs shared on Twitter. The model classifies the content of the URLs, identifying patterns, trends, and key information that can be used for various business or social insights.</p>

                    <h2>Technologies Used</h2>
                    <p>Python, scikit-learn, Natural Language Processing (NLP), Twitter API</p>
        
                    <h2>Results</h2>
                    <p>The model provided 88% accuracy in classifying Twitter URLs, helping companies and organizations extract actionable insights from social media data.</p>
                </div>
            </section>
        </div>

        <a href="index.html" class="home-button">Home</a> <!-- Home Button -->
    </section>

    <!-- Footer -->
    <footer class="footer-section">
        <p>&copy; 2024 Nithin Rontala. All rights reserved.</p>
    </footer>
</body>
</html>
